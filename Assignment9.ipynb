{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c2ede3-313f-4488-8065-553006a1efa6",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "### Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports, technology, food, books, etc.).\n",
    "1. Convert text to lowercase and remove punctuaƟon.\n",
    "2. Tokenize the text into words and sentences.\n",
    "3. Remove stopwords (using NLTK's stopwords list).\n",
    "4. Display word frequency distribuƟon (excluding stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe0056b-d290-4f14-bb39-9684e86fdda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab118907-6830-4a80-b3b5-db101ec4f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"\n",
    "Anime is such a unique and vibrant medium — it brings together amazing storytelling and eye-catching visuals in a way that's hard to match. \n",
    "Whether you're into high-energy adventures like Demon Slayer or prefer the calm, cozy vibes of something like Yuru Camp, there's genuinely something for everyone. \n",
    "What makes anime really special is how it can tap into deep emotions and tell stories that go beyond language and borders. \n",
    "Newer shows keep raising the bar, pushing what animation can do and how stories are told. \n",
    "At the end of the day, anime isn't just about entertainment — it's a form of art and culture that connects with people all over the world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3cd1155-77b3-41d6-902e-b4513ec1950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "anime is such a unique and vibrant medium — it brings together amazing storytelling and eyecatching visuals in a way thats hard to match \n",
      "whether youre into highenergy adventures like demon slayer or prefer the calm cozy vibes of something like yuru camp theres genuinely something for everyone \n",
      "what makes anime really special is how it can tap into deep emotions and tell stories that go beyond language and borders \n",
      "newer shows keep raising the bar pushing what animation can do and how stories are told \n",
      "at the end of the day anime isnt just about entertainment — its a form of art and culture that connects with people all over the world\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "text_low = sentence.lower()\n",
    "no_punc = text_low.translate(str.maketrans('', '', string.punctuation))\n",
    "print(no_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e71e258-fca7-45b3-8601-f8a994fc4ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2519cfc0-eacc-430e-bff6-12762151e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words:   ['anime', 'is', 'such', 'a', 'unique', 'and', 'vibrant', 'medium', '—', 'it', 'brings', 'together', 'amazing', 'storytelling', 'and', 'eyecatching', 'visuals', 'in', 'a', 'way', 'thats', 'hard', 'to', 'match', 'whether', 'youre', 'into', 'highenergy', 'adventures', 'like', 'demon', 'slayer', 'or', 'prefer', 'the', 'calm', 'cozy', 'vibes', 'of', 'something', 'like', 'yuru', 'camp', 'theres', 'genuinely', 'something', 'for', 'everyone', 'what', 'makes', 'anime', 'really', 'special', 'is', 'how', 'it', 'can', 'tap', 'into', 'deep', 'emotions', 'and', 'tell', 'stories', 'that', 'go', 'beyond', 'language', 'and', 'borders', 'newer', 'shows', 'keep', 'raising', 'the', 'bar', 'pushing', 'what', 'animation', 'can', 'do', 'and', 'how', 'stories', 'are', 'told', 'at', 'the', 'end', 'of', 'the', 'day', 'anime', 'isnt', 'just', 'about', 'entertainment', '—', 'its', 'a', 'form', 'of', 'art', 'and', 'culture', 'that', 'connects', 'with', 'people', 'all', 'over', 'the', 'world'] \n",
      "\n",
      "Tokenized Sentences:   [\"\\nAnime is such a unique and vibrant medium — it brings together amazing storytelling and eye-catching visuals in a way that's hard to match.\", \"Whether you're into high-energy adventures like Demon Slayer or prefer the calm, cozy vibes of something like Yuru Camp, there's genuinely something for everyone.\", 'What makes anime really special is how it can tap into deep emotions and tell stories that go beyond language and borders.', 'Newer shows keep raising the bar, pushing what animation can do and how stories are told.', \"At the end of the day, anime isn't just about entertainment — it's a form of art and culture that connects with people all over the world.\"] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(no_punc)\n",
    "sent = sent_tokenize(sentence)\n",
    "print(\"Tokenized words:  \", words,\"\\n\")\n",
    "print(\"Tokenized Sentences:  \", sent,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b03bed-d826-4e1b-8b09-6bc742c95667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopper = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f21f29-e0f5-425b-ad6b-97feb0757d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Word Tokens:\n",
      " ['anime', 'unique', 'vibrant', 'medium', '—', 'brings', 'together', 'amazing', 'storytelling', 'eyecatching', 'visuals', 'way', 'thats', 'hard', 'match', 'whether', 'youre', 'highenergy', 'adventures', 'like', 'demon', 'slayer', 'prefer', 'calm', 'cozy', 'vibes', 'something', 'like', 'yuru', 'camp', 'theres', 'genuinely', 'something', 'everyone', 'makes', 'anime', 'really', 'special', 'tap', 'deep', 'emotions', 'tell', 'stories', 'go', 'beyond', 'language', 'borders', 'newer', 'shows', 'keep', 'raising', 'bar', 'pushing', 'animation', 'stories', 'told', 'end', 'day', 'anime', 'isnt', 'entertainment', '—', 'form', 'art', 'culture', 'connects', 'people', 'world'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopper_removed = [w for w in words if w not in stopper]\n",
    "print(\"Filtered Word Tokens:\\n\", stopper_removed ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b7aa6f-0141-43ef-8c21-ac3fe7a8e75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Frequency Distribution:\n",
      "anime: 3\n",
      "unique: 1\n",
      "vibrant: 1\n",
      "medium: 1\n",
      "—: 2\n",
      "brings: 1\n",
      "together: 1\n",
      "amazing: 1\n",
      "storytelling: 1\n",
      "eyecatching: 1\n",
      "visuals: 1\n",
      "way: 1\n",
      "thats: 1\n",
      "hard: 1\n",
      "match: 1\n",
      "whether: 1\n",
      "youre: 1\n",
      "highenergy: 1\n",
      "adventures: 1\n",
      "like: 2\n",
      "demon: 1\n",
      "slayer: 1\n",
      "prefer: 1\n",
      "calm: 1\n",
      "cozy: 1\n",
      "vibes: 1\n",
      "something: 2\n",
      "yuru: 1\n",
      "camp: 1\n",
      "theres: 1\n",
      "genuinely: 1\n",
      "everyone: 1\n",
      "makes: 1\n",
      "really: 1\n",
      "special: 1\n",
      "tap: 1\n",
      "deep: 1\n",
      "emotions: 1\n",
      "tell: 1\n",
      "stories: 2\n",
      "go: 1\n",
      "beyond: 1\n",
      "language: 1\n",
      "borders: 1\n",
      "newer: 1\n",
      "shows: 1\n",
      "keep: 1\n",
      "raising: 1\n",
      "bar: 1\n",
      "pushing: 1\n",
      "animation: 1\n",
      "told: 1\n",
      "end: 1\n",
      "day: 1\n",
      "isnt: 1\n",
      "entertainment: 1\n",
      "form: 1\n",
      "art: 1\n",
      "culture: 1\n",
      "connects: 1\n",
      "people: 1\n",
      "world: 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "frequency_dist = FreqDist(stopper_removed)\n",
    "print(\"\\nWord Frequency Distribution:\")\n",
    "for word, frequency in frequency_dist.items():\n",
    "    print(f\"{word}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910039f1-ab9c-4a29-8c5a-8c3f1a488b4c",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "### Stemming and Lemmatization\n",
    "1. Take the tokenized words from QuesƟon 1 (aŌer stopword removal).\n",
    "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
    "3. Apply lemmaƟzaƟon using NLTK's WordNetLemmaƟzer.\n",
    "4. Compare and display results of both techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73d1f7d-bb88-40a6-9eda-13bd1452b3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') #lematizer\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "portered = [porter.stem(w) for w in stopper_removed]\n",
    "lancastered = [lancaster.stem(w) for w in stopper_removed]\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in stopper_removed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dcdf1ec-56fc-496e-8efc-491dd2089bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original            Porter              Lancaster           Lemma              \n",
      "------------------------------------------------------------\n",
      "anime               anim                anim                anime              \n",
      "unique              uniqu               un                  unique             \n",
      "vibrant             vibrant             vibr                vibrant            \n",
      "medium              medium              med                 medium             \n",
      "—                   —                   —                   —                  \n",
      "brings              bring               bring               brings             \n",
      "together            togeth              togeth              together           \n",
      "amazing             amaz                amaz                amazing            \n",
      "storytelling        storytel            storytel            storytelling       \n",
      "eyecatching         eyecatch            eyecatch            eyecatching        \n",
      "visuals             visual              vis                 visuals            \n",
      "way                 way                 way                 way                \n",
      "thats               that                that                thats              \n",
      "hard                hard                hard                hard               \n",
      "match               match               match               match              \n",
      "whether             whether             wheth               whether            \n",
      "youre               your                yo                  youre              \n",
      "highenergy          highenergi          highenergy          highenergy         \n",
      "adventures          adventur            adv                 adventure          \n",
      "like                like                lik                 like               \n",
      "demon               demon               demon               demon              \n",
      "slayer              slayer              slay                slayer             \n",
      "prefer              prefer              pref                prefer             \n",
      "calm                calm                calm                calm               \n",
      "cozy                cozi                cozy                cozy               \n",
      "vibes               vibe                vib                 vibe               \n",
      "something           someth              someth              something          \n",
      "like                like                lik                 like               \n",
      "yuru                yuru                yuru                yuru               \n",
      "camp                camp                camp                camp               \n",
      "theres              there               ther                there              \n",
      "genuinely           genuin              genuin              genuinely          \n",
      "something           someth              someth              something          \n",
      "everyone            everyon             everyon             everyone           \n",
      "makes               make                mak                 make               \n",
      "anime               anim                anim                anime              \n",
      "really              realli              real                really             \n",
      "special             special             spec                special            \n",
      "tap                 tap                 tap                 tap                \n",
      "deep                deep                deep                deep               \n",
      "emotions            emot                emot                emotion            \n",
      "tell                tell                tel                 tell               \n",
      "stories             stori               story               story              \n",
      "go                  go                  go                  go                 \n",
      "beyond              beyond              beyond              beyond             \n",
      "language            languag             langu               language           \n",
      "borders             border              bord                border             \n",
      "newer               newer               new                 newer              \n",
      "shows               show                show                show               \n",
      "keep                keep                keep                keep               \n",
      "raising             rais                rais                raising            \n",
      "bar                 bar                 bar                 bar                \n",
      "pushing             push                push                pushing            \n",
      "animation           anim                anim                animation          \n",
      "stories             stori               story               story              \n",
      "told                told                told                told               \n",
      "end                 end                 end                 end                \n",
      "day                 day                 day                 day                \n",
      "anime               anim                anim                anime              \n",
      "isnt                isnt                isnt                isnt               \n",
      "entertainment       entertain           entertain           entertainment      \n",
      "—                   —                   —                   —                  \n",
      "form                form                form                form               \n",
      "art                 art                 art                 art                \n",
      "culture             cultur              cult                culture            \n",
      "connects            connect             connect             connects           \n",
      "people              peopl               peopl               people             \n",
      "world               world               world               world              \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Original':<19} {'Porter':<19} {'Lancaster':<19} {'Lemma':<19}\")\n",
    "print(\"-\" * 60)\n",
    "for o, p, l, le in zip(stopper_removed, portered, lancastered, lemmatized):\n",
    "    print(\"{:<19} {:<19} {:<19} {:<19}\".format(o, p, l, le))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f3f33a-5e64-4d4b-8ae4-6ce4e8665250",
   "metadata": {},
   "source": [
    "# Question 3. Regular Expressions and Text Spliƫng\n",
    "1. Take their original text from Question 1.\n",
    "2. Use regular expressions to:\n",
    " \n",
    "    - a. Extract all words with more than 5 letters.\n",
    " \n",
    "    - b. Extract all numbers (if any exist in their text).\n",
    " \n",
    "    - c. Extract all capitalized words.\n",
    "3. Use text spliƫng techniques to:\n",
    "   \n",
    "    - a. Split the text into words containing only alphabets (removing digits and specialcharacters).\n",
    "    - b. Extract words starting with a vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c9b492d-7dfb-492d-9182-135ac4aedc5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words (>5) letters:   ['unique', 'vibrant', 'medium', 'brings', 'together', 'amazing', 'storytelling', 'eyecatching', 'visuals', 'whether', 'highenergy', 'adventures', 'slayer', 'prefer', 'something', 'theres', 'genuinely', 'something', 'everyone', 'really', 'special', 'emotions', 'stories', 'beyond', 'language', 'borders', 'raising', 'pushing', 'animation', 'stories', 'entertainment', 'culture', 'connects', 'people'] \n",
      "\n",
      "\n",
      "Numbers :   [] \n",
      "\n",
      "\n",
      "Capitalized :   ['Anime', 'Whether', 'Demon', 'Slayer', 'Yuru', 'Camp', 'What', 'Newer', 'At'] \n",
      "\n",
      "\n",
      "Only alpha words:   ['anime', 'is', 'such', 'a', 'unique', 'and', 'vibrant', 'medium', 'it', 'brings', 'together', 'amazing', 'storytelling', 'and', 'eyecatching', 'visuals', 'in', 'a', 'way', 'thats', 'hard', 'to', 'match', 'whether', 'youre', 'into', 'highenergy', 'adventures', 'like', 'demon', 'slayer', 'or', 'prefer', 'the', 'calm', 'cozy', 'vibes', 'of', 'something', 'like', 'yuru', 'camp', 'theres', 'genuinely', 'something', 'for', 'everyone', 'what', 'makes', 'anime', 'really', 'special', 'is', 'how', 'it', 'can', 'tap', 'into', 'deep', 'emotions', 'and', 'tell', 'stories', 'that', 'go', 'beyond', 'language', 'and', 'borders', 'newer', 'shows', 'keep', 'raising', 'the', 'bar', 'pushing', 'what', 'animation', 'can', 'do', 'and', 'how', 'stories', 'are', 'told', 'at', 'the', 'end', 'of', 'the', 'day', 'anime', 'isnt', 'just', 'about', 'entertainment', 'its', 'a', 'form', 'of', 'art', 'and', 'culture', 'that', 'connects', 'with', 'people', 'all', 'over', 'the', 'world'] \n",
      "\n",
      "Only alpha words:\n",
      " ['anime', 'is', 'such', 'a', 'unique', 'and', 'vibrant', 'medium', 'it', 'brings', 'together', 'amazing', 'storytelling', 'and', 'eyecatching', 'visuals', 'in', 'a', 'way', 'thats', 'hard', 'to', 'match', 'whether', 'youre', 'into', 'highenergy', 'adventures', 'like', 'demon', 'slayer', 'or', 'prefer', 'the', 'calm', 'cozy', 'vibes', 'of', 'something', 'like', 'yuru', 'camp', 'theres', 'genuinely', 'something', 'for', 'everyone', 'what', 'makes', 'anime', 'really', 'special', 'is', 'how', 'it', 'can', 'tap', 'into', 'deep', 'emotions', 'and', 'tell', 'stories', 'that', 'go', 'beyond', 'language', 'and', 'borders', 'newer', 'shows', 'keep', 'raising', 'the', 'bar', 'pushing', 'what', 'animation', 'can', 'do', 'and', 'how', 'stories', 'are', 'told', 'at', 'the', 'end', 'of', 'the', 'day', 'anime', 'isnt', 'just', 'about', 'entertainment', 'its', 'a', 'form', 'of', 'art', 'and', 'culture', 'that', 'connects', 'with', 'people', 'all', 'over', 'the', 'world']\n",
      "\n",
      "Words starting with vowels:\n",
      " ['anime', 'is', 'a', 'unique', 'and', 'it', 'amazing', 'and', 'eyecatching', 'in', 'a', 'into', 'adventures', 'or', 'of', 'everyone', 'anime', 'is', 'it', 'into', 'emotions', 'and', 'and', 'animation', 'and', 'are', 'at', 'end', 'of', 'anime', 'isnt', 'about', 'entertainment', 'its', 'a', 'of', 'art', 'and', 'all', 'over']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "letter_5 = re.findall(r'\\b\\w{6,}\\b', no_punc)\n",
    "print(\"words (>5) letters:  \", letter_5 ,'\\n')\n",
    "# \\w{6,} = Match any word (\\w) with 6 or more characters.\n",
    "\n",
    "numb = re.findall(r'\\b\\d+\\b', no_punc)\n",
    "print(\"\\nNumbers :  \", numb,'\\n')\n",
    "# \\d+ = One or more digits (0-9)\n",
    "\n",
    "caps = re.findall(r'\\b[A-Z][a-zA-Z]*\\b', sentence)\n",
    "print(\"\\nCapitalized :  \", caps, '\\n')\n",
    "# [a-zA-Z]* = Followed by zero or more letters (upper/lower case).\n",
    "\n",
    "alphas = re.findall(r'\\b[a-zA-Z]+\\b', no_punc)\n",
    "print(\"\\nOnly alpha words:  \", alphas, '\\n')\n",
    "# [a-zA-Z]+ = One or more alphabet characters (no digits or symbols).\n",
    "\n",
    "# text into words \n",
    "words_list = no_punc.split()\n",
    "only_alpha_words = [w for w in words_list if w.isalpha()]\n",
    "print(\"Only alpha words:\\n\", only_alpha_words)\n",
    "\n",
    "vowelss = [w for w in alphas if w[0].lower() in 'aeiou']\n",
    "print(\"\\nWords starting with vowels:\\n\", vowelss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a84f3-f396-475f-ab62-cdf9f3ea6ed7",
   "metadata": {},
   "source": [
    "# Q4. Custom Tokenization & Regex-based Text Cleaning\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Input**: Use the original text from **Question 1**.\n",
    "\n",
    "2. **Custom Tokenization Function Requirements**:\n",
    "   \n",
    "   - **(a)** Remove punctuation and special symbols, **but keep contractions** (e.g., `\"isn't\"` should remain `\"isn't\"` and not split into `\"is\"` and `\"n't\"`).\n",
    "   \n",
    "   - **(b)** Handle **hyphenated words** as **single tokens** (e.g., `\"state-of-the-art\"` should remain as one token).\n",
    "   \n",
    "   - **(c)** **Tokenize numbers separately**, but **keep decimal numbers intact** (e.g., `\"3.14\"` should remain `\"3.14\"`).\n",
    "\n",
    "3. **Regex Substitutions** (using `re.sub`):\n",
    "\n",
    "   - **(a)** Replace **email addresses** with the placeholder `<EMAIL>`.\n",
    "   \n",
    "   - **(b)** Replace **URLs** with the placeholder `<URL>`.\n",
    "   \n",
    "   - **(c)** Replace **phone numbers** (formats like `123-456-7890` or `+91 9876543210`) with the plceho-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\n",
    "placeholder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ba0f752-0f2b-4d70-b76d-b5b16fd6cc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Tokens:   ['Anime', 'is', 'such', 'a', 'unique', 'and', 'vibrant', 'medium', 'it', 'brings', 'together', 'amazing', 'storytelling', 'and', 'eye-catching', 'visuals', 'in', 'a', 'way', \"that's\", 'hard', 'to', 'match', 'Whether', \"you're\", 'into', 'high-energy', 'adventures', 'like', 'Demon', 'Slayer', 'or', 'prefer', 'the', 'calm', 'cozy', 'vibes', 'of', 'something', 'like', 'Yuru', 'Camp', \"there's\", 'genuinely', 'something', 'for', 'everyone', 'What', 'makes', 'anime', 'really', 'special', 'is', 'how', 'it', 'can', 'tap', 'into', 'deep', 'emotions', 'and', 'tell', 'stories', 'that', 'go', 'beyond', 'language', 'and', 'borders', 'Newer', 'shows', 'keep', 'raising', 'the', 'bar', 'pushing', 'what', 'animation', 'can', 'do', 'and', 'how', 'stories', 'are', 'told', 'At', 'the', 'end', 'of', 'the', 'day', 'anime', \"isn't\", 'just', 'about', 'entertainment', \"it's\", 'a', 'form', 'of', 'art', 'and', 'culture', 'that', 'connects', 'with', 'people', 'all', 'over', 'the', 'world'] \n",
      "\n",
      "\n",
      "Text after Regex Substitutions:\n",
      " \n",
      "Anime is such a unique and vibrant medium — it brings together amazing storytelling and eye-catching visuals in a way that's hard to match. \n",
      "Whether you're into high-energy adventures like Demon Slayer or prefer the calm, cozy vibes of something like Yuru Camp, there's genuinely something for everyone. \n",
      "What makes anime really special is how it can tap into deep emotions and tell stories that go beyond language and borders. \n",
      "Newer shows keep raising the bar, pushing what animation can do and how stories are told. \n",
      "At the end of the day, anime isn't just about entertainment — it's a form of art and culture that connects with people all over the world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Custom Tokenizer\n",
    "def custom_tokens(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s\\-']\", \"\", text)\n",
    "    tokens = re.findall(r\"\\b\\w+(?:[-']\\w+)*\\b\", text)\n",
    "    # ?: = Non-capturing group (just groups the pattern, doesn't save it separately)\n",
    "    return tokens\n",
    "customs = custom_tokens(sentence)\n",
    "print(\"\\nCustom Tokens:  \", customs, '\\n')\n",
    "\n",
    "\n",
    "text_replaced = re.sub(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', '<EMAIL>', sentence)\n",
    "# [\\w.-]+?\tOne or more word characters (a-z, A-Z, 0-9, _), dot ., or hyphen - (email username part)\n",
    "# \\w+?\tDomain name (like gmail) and then the domain extension\n",
    "\n",
    "text_replaced = re.sub(r'http[s]?://\\S+', '<URL>', text_replaced)\n",
    "# http[s]?\tMatch http or https (the s? means \"s\" is optional)\n",
    "# \\S+\tMatch one or more non-space characters (the URL itself)\n",
    "\n",
    "text_replaced = re.sub(r'(\\+?\\d{1,2}\\s?)?(\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4})', '<PHONE>', text_replaced)\n",
    "# (\\+?\\d{1,2}\\s?)? – The entire pattern is optional due to the outer ()\n",
    "# \\+?  Matches an optional plus sign (+)\n",
    "# \\d{1,2}  Matches 1 or 2 digits (0-9)\n",
    "# \\s?   Matches an optional whitespace character (like a space or tab)\n",
    "# [-\\s]?   Optional hyphen or space (separator)\n",
    "# \\d{4}\tExactly 4 digits (last part)\n",
    "print(\"\\nText after Regex Substitutions:\\n\", text_replaced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d4c7e-1fef-4ce9-ae77-e8e8b93897e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
